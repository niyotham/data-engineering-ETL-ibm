# data-engineering-ETL-ibm
extract transform and load
## Project Overview
### Scenario
Tracks stock prices, commodities, forex rates, inflation rates.  Your job is to extract financial data from various sources like websites, APIs and files provided by various financial analysis firms. After you collect the data, you extract the data of interest to your company and transform it based on the requirements given to you. Once the transformation is complete you load that data into a database.

### Project Tasks
 In this project you will:

- [x] Collect data using APIs

- [x] Collect data using webscraping.

- [x]  Download files to process.    

- [x]  Read csv, xml and json file types.

- [x]  Extract data from the above file types.

- [x]  Transform data.

- [x]  Use the built in logging module.

- [x]  Save the transformed data in a ready-to-load format which data engineers can use to load the data.

# Apply transformation and use airlfow for task scheduling
Extract transform and load and transform tasks flow in airflow GUI

[tasks0(https://github.com/niyotham/data-engineering-ETL-ibm/blob/main/Course%2008%20-%20ETL%20and%20Data%20Pipelines%20with%20Shell%2C%20Airflow%20and%20Kafka/images/Untitled.png)


